from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.preprocessing import image
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from PIL import Image
import numpy as np
import io
import base64
from IPython.display import display, HTML

# Define image size
IMG_SIZE = (224, 224)
DISPLAY_WIDTH = 150  # Adjust this value to set the desired width of the displayed images

# Load MobileNetV2 model pre-trained on ImageNet
base_model = MobileNetV2(weights='imagenet', include_top=False)
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(1, activation='sigmoid')(x)
model = Model(inputs=base_model.input, outputs=predictions)
#pmpgowthami2k4
# Initialize empty lists for all images
all_images = []

# Function to handle file selection
def handle_file_selection(files):
    for file, img_data in files.items():
        # Get the image data directly
        img_data = files[file]

        # Pre-process the image
        img = Image.open(io.BytesIO(img_data))
        img = img.resize(IMG_SIZE)  # Resize to match model input size
        img = image.img_to_array(img)
        img = preprocess_input(img)
        img = np.expand_dims(img, axis=0)

        # Predict the health of the banana leaf
        prediction = model.predict(img)[0][0]

        # Debugging information
        print(f"File: {file}, Prediction: {prediction}")

        # Classify the image based on the predicted label
        predicted_label = "Healthy" if prediction < 0.5 else "Unhealthy"

        # Calculate the confidence of the prediction
        confidence = prediction if predicted_label == "Healthy" else 1 - prediction

        # Append the file name, predicted label, and image to the corresponding list
        all_images.append((file, img_data, predicted_label, confidence))

# Use a simple file selection widget
from google.colab import files

uploaded = files.upload()

# Process selected files
handle_file_selection(uploaded)  # Pass the entire uploaded dictionary

# Display results for all images
html_output = "<h2>All Banana Leaves:</h2>"
for image_info in all_images:
    encoded_image = base64.b64encode(image_info[1]).decode("utf-8")
    predicted_label = image_info[2]
    confidence = image_info[3]
    html_output += (
        f"<img src='data:image/webp;base64,{encoded_image}' style='width:{DISPLAY_WIDTH}px;' /> "
        f"<span style='font-size:12px;'>Predicted Label: {predicted_label}, Confidence: {confidence:.2%}</span><br>"
    )

# Display the HTML output
display(HTML(html_output))

# Display the HTML output
display(HTML(html_output))
